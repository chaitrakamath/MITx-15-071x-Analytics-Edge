str(Carseats)
ls()
High
High = ifelse(Sales <  0.8, 'No', 'Yes')
High
High = ifelse(Sales <  8, 'No', 'Yes')
High
str(Carseats)
Carseats = data.frame(Carseats, High)
str(Carseats)
tree.carseats = tree(High ~ . - Sales, data = Carseats)
summary(tree.carseats)
plot(tree.carseats)
text(tree.carseats)
unique(Carseats$ShelveLoc)
text(tree.carseats, pretty = 0)
tree.carseats
set.seed(2)
train = sample(1: nrow(Carseats),200)
Carseats.test = Carseats[-train, ]
High.test = High[-train, ]
High.test = High[-train]
head(High)
tree.carseats = tree(High ~ . - Sales, data = Carseats, subset = train)
tree.pred = predict(tree.carseats, Carseats.test, type = 'class')
table(tree.pred)
table(tree.pred, High.test)
set.seed(3)
cv.carseats = cv.tree(tree.carseats, FUN = prune.misclass)
names(cv.carseats)
cv.carseats
part(mfrow = c(1, 2))
par(mfrow = c(1, 2))
plot(cv.carseats$size, cv.carseats$dev, type = 'b')
plot(cv.carseats$k, cv.carseats$dev, type = 'b')
prune.carseats = prune.misclass(tree.carseats, best = 9)
plot(prune.carseats)
text(prune.carseats, pretty = 0)
tree.pred = predict(prune.carseats, Carseats.test, type = 'class')
table(tree.pred, Carseats.test)
table(tree.pred, High.test)
prune.carseats = prune.misclass(tree.carseats, best = 15)
plot(prune.carseats)
text(prune.carseats, pretty = 0)
tree.pred = predict(prune.carseats, Carseats.test, type = 'class')
table(tree.pred, High.test)
library(MASS)
set.seed(1)
train = sample(1:nrow(Boston), nrow(Boston) / 2)
len(train)
str(train)
str(Boston)
length(train)
tree.boston = tree(medv ~ ., data = Boston, subset = train)
summary(tree.boston)
plot(tree.boston)
text (tree.boston, pretty = 0)
cv.boston = cv.tree(tree.boston)
cv.boston
plot(cv.boston$dev ~ cv.boston$size, type = 'b')
prune.boston = prune.tree(tree.boston, best = 8)
prune.boston = prune.tree(tree.boston, best = 5)
plot(prune.boston)
text(prube.boston, pretty = 0)
text(prune.boston, pretty = 0)
yhat = predict(tree.boston, newdata = Boston[-train])
yhat = predict(tree.boston, newdata = Boston[-train,])
boston.test = Boston[-train, 'medv']
plot(yhat, boston.test)
abline(o,1)
abline(0,1)
library(randomForest)
install.packages('randomForests')
library(randomForest)
install.packages('randomForest')
library(randomForest)
set.seed(1)
bag.boston = randomForest(medv ~ ., data = Boston, subset = train, mtry = 13, importance = TRUE)
bag.boston
?randomForest()
str(Boston)
yhat.bag = predict(bag.boston, newdata = Boston[-train,])
plot(yhat.bag, boston.test)
abline(0,1)
bag.boston = randomForest(medv ~ ., data = Boston, subset = train, mtry = 13, importance = TRUE, ntree = 25)
bag.boston
set.seed(1)
rf.boston = randomForest(medv ~ ., data = Boston, mtry = 6, importance = TRUE)
rf.boston = randomForest(medv ~ ., data = Boston, subset = train, mtry = 6, importance = TRUE)
rf.boston
yhat.rf = predict(rf.boston, newdata = Boston[-train,])
mean((yhat.rf - boston.test) ^ 2)
importance (bag.boston)
varImpPlot(rf.boston)
install.packages('gbm')
library(gbm)
set.seed(1)
boost.boston = gbm(medv ~ ., data = Boston[train, ], ntrees = 5000, distribution = 'gaussian', interaction.depth = 4)
boost.boston = gbm(medv ~ ., data = Boston[train, ], n.trees = 5000, distribution = 'gaussian', interaction.depth = 4)
boost.boston = gbm(medv ~ ., data = Boston, subset = train, n.trees = 5000, distribution = 'gaussian', interaction.depth = 4)
boost.boston = gbm(medv ~ ., data = Boston[train, ], n.trees = 5000, distribution = 'gaussian', interaction.depth = 4)
summary(boost.boston)
par(mfrow=c(1,2))
plot(boost.boston, i = 'rm')
plot(boost.boston, i = 'lstat')
yhat.boost = predict(boost.boston, newdata = Boston[-train,], n.trees = 5000)
mean((yhat.boston - Boston[-train, medv]) ^ 2)
mean((yhat.boost - Boston[-train, medv]) ^ 2)
mean((yhat.boost - Boston[-train, 'medv']) ^ 2)
boost.boston = gbm(medv ~ ., data = Boston[train, ], n.trees = 5000, distribution = 'gaussian', interaction.depth = 4, shrinkage = 0.2, verbose = False)
boost.boston = gbm(medv ~ ., data = Boston[train, ], n.trees = 5000, distribution = 'gaussian', interaction.depth = 4, shrinkage = 0.2, verbose = FALSE)
yhat.boost = predict(boost.boston, newdata = Boston[-train,], n.trees = 5000)
mean((yhat.boost - Boston[-train, 'medv']) ^ 2)
install.packages ('boot')
library(boot)
sample(3, replace = T)
set.seed(1)
x = matrix(rnorm(20 * 2), ncol = 2)
x
y = c(rep(-1, 10), rep (1,10))
y
x[y == 1, ] = x[y == 1, ] + 1
x
plot(x, col = (3 - y))
plot (x)
plot(x, col = (3 - y))
dat = data.frame(x, y = as.factor(y))
install.packages('e1071')
library(e1071)
svmfit = svm (y ~ ., data = dat, cost = 10, kernel = 'linear', scale = FALSE)
plot(svmfit, dat)
plot.svm(svmfit, dat)
dat
names(svmfit)
svmfit$index
summary(svmfit)
svmfit = svm (y ~ ., data = dat, cost = 0.1, kernel = 'linear', scale = FALSE)
plot(svmfit, dat)
svmfit$index
summary(svmfit)
set.seed(1)
tune.out = tune(svm, y ~ ., data = dat, kernel = 'linear', ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100,)))
tune.out = tune(svm, y ~ ., data = dat, kernel = 'linear', ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100)))
tune.out=tune(svm,y∼.,data=dat,kernel="linear",              ranges=list(cost=c(0.001, 0.01, 0.1, 1,5,10,100)))
tune.out=tune(svm,y∼.,data=dat,kernel="linear",ranges=list(cost=c(0.001, 0.01, 0.1, 1,5,10,100)))
tune.out=tune(svm,y ~.,data=dat,kernel="linear",ranges=list(cost=c(0.001, 0.01, 0.1, 1,5,10,100)))
?tune()
tune.out = tune(svm, y~., data = dat, ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100)), kernel = 'linear')
tune(svm, Species~., data = iris, ranges = list(gamma = 2^(-1:1), cost = 2^(2:4)),tunecontrol = tune.control(sampling = "fix"))
xtest = matrix(rnorm(20 * 2), ncol = 2)
ytest = sample(c(-1, 1), 20, rep = TRUE)
xtest[ytest == 1, ] = xtest[ytest == 1, ] + 1
testdat = data.frame(xtest, ytest = as.factor(ytest))
bestmod = svm(y ~ ., data = dat, kernel = 'linear', cost = 0.1)
ypred = predict(bestmod, newdata = testdat)
ypred
table(predict = ypred, truth = testdat$ytest)
bestmod = svm(y ~ ., data = dat, kernel = 'linear', cost = 0.1, scale = FALSE)
ypred = predict(bestmod, newdata = testdat)
table(predict = ypred, truth = testdat$ytest)
svmfit = svm(y ~ ., data = dat, kernel = 'linear', cost = 0.01, scale = FALSE)
set.seed(1)
bestmod = svm(y ~ ., data = dat, kernel = 'linear', cost = 0.1, scale = FALSE)
xtest = matrix(rnorm(20 * 2), ncol = 2)
ytest = sample(c(-1, 1), 20, rep = TRUE)
xtest[ytest == 1, ] = xtest[ytest == 1, ] + 1
bestmod = svm(y ~ ., data = dat, kernel = 'linear', cost = 0.1, scale = FALSE)
table(predict = ypred, truth = testdat$ytest)
ypred = predict(svmfit, newdata = testdat)
table(ypred, testdat$ytest)
x[y == 1, ] = x[y == 1, ] + 0.5
plot(x, col = (y + 5) / 2, pch = 19)
dat = data.frame(x, y = as.factor(y))
svmfit = svm(y ~ ., data = dat, kernle = 'linear', cost = 1e5)
summary(svmfit)
plot(svmfit, dat)
svmfit = svm(y ~ ., data = dat, kernle = 'linear', cost = 1)
summary(svmfit)
plot(svmfit, dat)
set.seed(1)
x = matrix(rnorm(20 * 2), ncol = 2)
set.seed(1)
x = matrix(rnorm(200 * 2), ncol = 2)
x[1:100, ] = x[1:100, ] + 2
x[101:150, ] = x[101:150, ] - 2
?sample()
y = c(rep(1, 150), rep(2, 50))
dat = data.frame(x, y = as.factor(y))
plot(x, col = y)
train = sample(200, 100)
svmfit = svm (y ~ ., data = dat[train,], kernel = 'radial', gamma = 1, cost = 1)
plot(svmfit, dat[train,])
summary(svmfit)
svmfit = svm (y ~ ., data = dat[train,], kernel = 'radial', gamma = 1, cost = 1e5)
plot(svmfit, dat[train,])
summary(svmfit)
set.seed(1)
tune.out = tune(svm, y~., data = dat[train,], ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100)), gamma = c(0.5, 1, 2, 3, 4), kernel = 'radial')
set.seed(1)
tune.out=tune(svm, y~., data=dat[train,], kernel="radial",ranges=list(cost=c(0.1,1,10,100,1000),gamma=c(0.5,1,2,3,4) ))
tune.out=tune(svm, y~., data=dat[train,], kernel="radial",ranges=list(cost=c(0.1,1,10,100,100),gamma=c(0.5,1,2,3,4)))
set.seed(1)
bestmod = svm(y ~ ., data = dat[train,], cost = 1, gamma = 2, kernel = 'radial')
table(pred = predict(bestmod, newdata =dat[-train,]), true = dat[-train, 'y'])
library(ROCR)
install.packages('ROCR')
library(ROCR)
rocplot = function(pred, truth, ...){
predob = predict(pred, truth)
}
rocplot = function(pred, truth, ...){
predob = prediction(pred, truth)
perf = performance(predob, 'tpr', 'fpr')
plot(perf, ...)
}
svmfit.opt = svm (y ~ ., data = dat[train,], kernel = 'radial', gamma = 2, cost = 1, decision.values = TRUE)
fitted = attributes(svmfit.opt, newdata = dat[-train,], decision.values = TRUE)
fitted = attributes(predict(svmfit.opt, newdata = dat[-train,], decision.values = TRUE))
names(fitted)
fitted$decision.values
fitted$class
names(fitted)
fitted$levels
fitted$names
par(mfrow = c(1,2))
rocplot(fitted, dat[train, 'y'], main = 'Training data')
rocplot(fitted ,dat[train ,"y"],main="Training Data")
rocplot=function(pred, truth, ...){    predob = prediction (pred, truth)    perf = performance (predob , "tpr", "fpr") plot(perf ,...)}
rocplot=function(pred, truth, ...){predob = prediction (pred, truth)    perf = performance (predob , "tpr", "fpr") plot(perf ,...)}
rocplot=function(pred, truth, ...){
predob = prediction (pred, truth)
perf = performance (predob , "tpr", "fpr")
plot(perf ,...)
}
rocplot(fitted, dat[train, 'y'], main = 'Training data')
fitted$decision.values
length(fitted$decision.values)
length(dat[train, 'y'])
str(dat)
dat$y = as.numeric(levels(dat$y))
str(dat)
rocplot(fitted, dat[train, 'y'], main = 'Training data')
str(dat[train, 'y'])
str(fitted$decision.values)
as.numeric(fitted$decision.values)
str(as.numeric(fitted$decision.values))
rocplot(as.numeric(fitted$decision.values), dat[train, 'y'], main = 'Training data')
dat$y = as.factor(dat$y)
str(dat)
svmfit.flex = svm(y ~ ., data = dat[train, ], kernel = 'radial', gamma = 50, cost = 1, decision.values = T)
fitted = attributes(predict(svmfit.flex, newdata = dat[-train, y], decision.values = T))$decision.values
rocplot(fitted, dat[train, 'y'], add = 'T', col = 'red')
svmfit.opt = svm(y ~ ., data = dat[train,], kernel = 'radial', cost = 1, gamma = 2)
svmfit.opt = svm(y ~ ., data = dat[train,], kernel = 'radial', cost = 1, gamma = 2, decision.values = T)
fitted = attributes(predict(svmfit.opt, x[-train, 'y'], decision.values = T))$decision.values
fitted = attributes(predict(svmfit.opt, x[-train,], decision.values = T))$decision.values
rocplot(fitted, dat[-train, 'y'], main = 'Test Data')
fitted = attributes(predict(svmfit.flex, x[-train,], decision.values = T))$decision.values
rocplot(fitted, dat[-train, 'y'], add = 'T', col = 'red')
set.seed(1)
x = rbind(x, matrix(rnorm(50)))
x = rbind(x, matrix(rnorm(50*2), ncol = 2))
str(x
)
x
class(x)
y = c(y, rep(0, 50))
x[y == 0, ] = x[y == 0, ] + 2
dat = data.frame(x, as.factor(y))
par(mfrow= c(1, 2))
par(mfrow= c(1, 1))
plot(x, col = y)
plot(x, col = (y + 1))
plot(x, col = (y + 1))
plot(x, col = (y + 1))
plot(x, col = y)
plot(x, col = (y + 1))
smvfit = svm(y ~ ., data = dat, kernel = 'radial', cost = 10, gamma = 1)
plot(svmfit, dat)
library(ISLR)
names(Khan)
dim(xtrain)
dim(Khan$xtrain)
class(Khan)
class(Khan$xtrain)
dim(Khan$xtest)
length(Khan$ytrain)
length(Khan$ytest)
data = data.frame(x = Khan$xtrain, y = as.factor(Khan$ytrain))
head(data)
dat = data.frame(x = Khan$xtrain, y = as.factor(Khan$ytrain))
out = svm(ytrain ~ ., data = dat, kernel = 'linear', cost = 10)
out = svm(y ~ ., data = dat, kernel = 'linear', cost = 10)
summary(out)
plot(out, dat)
table(out$fitted, dat$y)
dat.test = data.frame(x = Khan$xtest, y = as.factor(Khan$ytest))
pred.test = predict(out, newdata = dat.test)
table(pred.test, dat.test$y)
rnorm(10, mean = 0)
rnorm(10, mean = 0, sd = diag(10))
rnorm(10, mean = 0, sd = diag(10))
rnorm(10, mean = 0, sd = diag(10))
rnorm(10, mean = 0, sd = diag(10))
rnorm(10, mean = 0, sd = diag(10))
matrix(rnorm(10, mean = 0, sd = diag(10),  10, 10)
)
matrix(rnorm(10, mean = 0, sd = diag(10)),  10, 10)
matrix(rnorm(100, mean = 0, sd = diag(10)),  10, 10)
diag(3)
matrix(rnorm(100, mean = rep(0,10), sd = diag(10)),  10, 10)
rep(0,10)
x2 = matrix(rnorm(100, mean = c(1,1,1,1,1,0,0,0,0,0), sd = diag(10)), 10, 10)
x2
y=rep(c(-1,1),c(10,10))
y
x1 = matrix(rnorm(100, mean = rep(0,10), sd = diag(10)),  10, 10)
x2 = matrix(rnorm(100, mean = c(1,1,1,1,1,0,0,0,0,0), sd = diag(10)), 10, 10)
x1
x2
rbind(x1, x2)
getwd()
setwd('/Users/admin/Documents/Coursera/AnalyticsEdge-edX/Week2/Assignment/Part1')
getwd()
setwd('/Users/admin/Documents/Coursera/AnalyticsEdge-edX/Week2/Assignment/Part1')
getwd()
climateChange = read.csv('climate_change.csv')
str(climateChange)
summary(climateChange)
train = climateChange$Year > 2006
head(train)
train = climateChange$Year < 2006
head(train)
train = climateChange$Year < 2006
length(train)
num = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
numBool = num >= 5
numBool
climateChange[numBool, ]
numBool = num <= 5
numBool
climateChange[numBool, ]
climateChange$Year >= 2006
climateTrain[climateChange$Year >= 2006, ]
climateChange[climateChange$Year >= 2006, ]
train = climateChange$Year >= 2006
length(train)
train = climateChange$Year <= 2006
length(train)
climateTrain = climateChange[-train,]
train = climateChange$Year <= 2006
length(train)
climateTrain = climateChange[train,]
length(climateTrain)
train
train = climateChange$Year <= 2006
length(train)
climateTrain = climateChange[train,]
length(climateTrain)
str(climateTrain)
climateTest = climateChange[-train, ]
str(climateTest)
num
numBool
num[-numBool]
-numBool
numBool
!numBool
train = climateChange$Year <= 2006
climateTrain = climateChange[train,]
str(climateTrain)
climateTest = climateChange[!train, ]
str(climateTest)
?lm
linModel = lm(Temp ~ .-(Year + Month), data = climateTrain)
summary(linModel)
cor(climateChange)
cor(climateChange)
cor(climateTrain)
cor(climateTrain)
names(climateTrain)
head(climateTrain[c("MEI", "CO2", "CH4", "N2O", "CFC.11", "CFC.12", "TSI", "Aerosols" ), ])
head(climateTrain[ , c("MEI", "CO2", "CH4", "N2O", "CFC.11", "CFC.12", "TSI", "Aerosols")])
cor(climateTrain[ , c("MEI", "CO2", "CH4", "N2O", "CFC.11", "CFC.12", "TSI", "Aerosols")])
limModel2 = lm(Temp ~ (MEI + TSI + Aerosols + N2O), data = climateTrain)
summary(linModel2)
linModel2 = lm(Temp ~ (MEI + TSI + Aerosols + N2O), data = climateTrain)
summary(linModel2)
linModel1 = lm(Temp ~ .-(Year + Month), data = climateTrain)
summary(linModel1)
summary(linModel2)
stepModel = step(linModel1)
summary(stepModel)
modelPred = predict(stepModel, newdata = climateTest)
summary(modelPred)
names(modelPred)
modelPred
table(modelPred, climateTest$Temp)
modelPred = predict(stepModel, newdata = climateTest)
SSE = sum((modelPred - climateTest$Temp) ^ 2)
SST = sum((climateTest$Temp - mean(climateTest$Temp)) ^ 2)
R2 = 1 - (SSE / SST)
R2
modelPred = predict(stepModel, newdata = climateTest)
SSE = sum((modelPred - climateTest$Temp) ^ 2)
SST = sum(mean(climateTraint$Temp) - climateTest$Temp) ^ 2)
SST = sum((mean(climateTraint$Temp) - climateTest$Temp) ^ 2)
SST = sum((mean(climateTrain$Temp) - climateTest$Temp) ^ 2)
R2 = 1 - (SSE / SST)
R2
getwd()
setwd('/Users/admin/Documents/Coursera/AnalyticsEdge-edX/Week2/Assignment/Part2')
getwd()
pisaTrain = read.csv('pisa2009train.csv')
pisaTest = read.csv('pisa2009test.csv')
str(pisaTrain)
tapply(pisaTrain$readingScore, pisaTrain$male == 1, mean, na.rm = TRUE)
summary(pisaTrain)
pisaTrain = na.omit(pisaTrain)
pisaTest = na.omit(pisaTest)
str(pisaTrain)
str(pisaTest)
pisaTrain$raceeth = relevel(pisaTrain$raceeth, 'White')
pisaTest$raceeth = relevel (pisaTest$raceeth, 'White')
lmScore = lm(readingScore ~ ., data = pisaTrain)
summary(lmScore)
sqrt(73.81)
mse = mean(residuals(lmScore) ^ 2)
rmse = sqrt(mse)
rmse
predTest = predict(lmScore, newdata = pisaTest)
summary(predTest)
names(summary(predTest))
summary(predTest)$Max - summary(predTest)$Min
637.7 - 353.2
SSE = sum((predTest - pisaTest$readingScore) ^ 2)
SST = sum((pisaTest$readingScore - mean(pisaTrain$readingScore)) ^ 2)
R2 = 1 - (SSE / SST)
R2
RMSE = sqrt(SSE / nrow(pisaTest))
RMSE
SST = sum((mean(pisaTrain$readingScore) - pisaTest$readingScore) ^ 2)
R2 = 1 - (SSE / SST)
R2
SSE
mean(pisaTrain$readingScore)
SST
getwd()
setwd('/Users/admin/Documents/Coursera/AnalyticsEdge-edX/Week2/Assignment/Part3')
getwd()
fluTrain = read.csv('FluTrain.csv')
str(fluTrain)
fluTrain[which.max(fluTrain$ILI), ]
head(fluTrain)
fluTrain[with(fluTrain, order(-ILI)),]
fluTrain[which.max(fluTrain$Queries),]
hist(fluTrain$ILI)
plot(log(fluTrain$ILI) ~ fluTrain$Queries, xlabel = 'Queries', ylabel = 'Log of ILI', main = 'ILI vs Queries')
fluTrend1 = lm(log(ILI) ~ Queries, data = fluTrain)
summary(fluTrend1)
fluTest = read.csv('FluTest.csv')
fluPred = exp(predict(fluTrend1, newdata = fluTest))
head(fluPred)
head(fluTest)
which(fluTest$Week == '2012-01-11 - 2012-03-18')
str(fluTest)
which(fluTest$Week == '2012-03-11 - 2012-03-18')
which(fluTest$Week == '2012-03-11 - 2012-03-17')
fluPred[which(fluTest$Week == '2012-03-11 - 2012-03-17'),]
fluPred[which(fluTest$Week == '2012-03-11 - 2012-03-17')]
obsILI = fluTest[which(fluTest$Week == '2012-03-11 - 2012-03-17'), 'ILI']
estimatedILI = fluPred[which(fluTest$Week == '2012-03-11 - 2012-03-17')]
obsILI
estimatedILI
(obsILI - estimatedILI) / obsILI
SSE = sum((fluTest$ILI - fluPred) ^ 2)
rmseTest = sqrt(SSE / nrow(fluTest))
rmseTest
install.packages('zoo')
ILILag2 = lag(zoo(fluTrain$ILI), -2, na.pad = TRUE)
library(zoo)
ILILag2 = lag(zoo(fluTrain$ILI), -2, na.pad = TRUE)
fluTrain$ILILag2 = coredata(ILILag2)
summary(fluTrain)
plot(fluTrain$ILILag2 ~ fluTrain$ILI)
fluTrend2 = lm(log(ILI) ~ (Queries + log(ILILag2)), data = fluTrain)
summary(fluTrend2)
ILILag2 = lag(zoo(fluTest$ILI), -2, na.pad = TRUE)
fluTest$ILILag2 = coredata(ILILag2)
summary(fluTest)
fluTest$IILILag2[1]
head(fluTest)
fluTest(1, 'ILILag2')
fluTest[1, 'ILILag2']
fluTest['2012-01-01 - 2012-01-07', 'ILILag2']
fluTest[3, 'ILILag2']
fluTest[1, 'ILILag2'] = 4
head(fluTest)
tail(fluTrain)
fluTrain[nrow(fluTrain), 'ILI']
fluTrain[nrow(fluTrain) - 1, 'ILI']
fluTest[1, 'ILILag2'] = fluTrain[nrow(fluTrain) - 1, 'ILI']
fluTest[2, 'ILILag2'] = fluTrain[nrow(fluTrain), 'ILI']
head(fluTest)
SSE
rmseTest
fluPred2 = predict(fluTrend2, newdata = fluTest)
fluPred2 = exp(predict(fluTrend2, newdata = fluTest))
SSE = sum((fluPred2 - fluTest$ILI) ^ 2)
SSE2 = sum((fluPred2 - fluTest$ILI) ^ 2)
rmseTest2 = sqrt (SSE / nrow(fluTest))
rmseTest2
