distances
mcols(distances)$distance
distances = distanceToNearest(HepG2, GM12878)
distances
mcols(distances)$distance < 2000
sum(mcols(distances)$distance < 2000)
sum(mcols(distances)$distance < 2000) / 303
sum(mcols(distances)$distance < 2000) / length(distances)
library(Homo.sapiens)
ghs = genes(Homo.sapiens)
ghs
mcols(ghs)
table(seqnames(ghs))
max(table(seqnames(ghs)))
which.max(table(seqnames(ghs)))
hist(width(ghs))
par(mfrow = c(1,1))
hist(width(ghs))
class(ghs)
median(width(ghs))
res = findOverlaps(HepG2,GM12878)
erbs = HepG2[queryHits(res)]
erbs = granges(erbs)
erbs2= intersect(HepG2,GM12878)
erbs
erbs2
library(Homo.sapiens)
ghs = genes(Homo.sapiens)
tss <- resize(ghs,1)
tss[unlist(mcols(tss)$GENEID==100113402),]
start(tss['100113402'])
library(ERBS)
data(HepG2)
data(GM12878)
res = findOverlaps(HepG2,GM12878)
erbs = HepG2[queryHits(res)]
erbs = granges(erbs)
erbs[4, ]
distanceToNearest(erbs[4, ], tss)
distances = distanceToNearest(erbs[4, ], tss)
subjectHits(distances)
index = subjectHits(distances)
tss[index]
?select()
?select
key = as.character(values(tss[index]$GENEID))
key
key = as.character(values(tss[index])$GENEID)
key
select(Homo.sapiens, keys = key, keytype = 'GENEID', columns = c('SYMBOL'))
library(ERBS)
data(HepG2)
data(GM12878)
res = findOverlaps(HepG2,GM12878)
erbs = HepG2[queryHits(res)]
erbs = granges(erbs)
erbs
genome(erbs)
erbs
library(BSgenome.Hsapiens.UCSC.hg19)
reqSeq = getSeq(erbs)
reqSeq = getSeq(erbs)
library(biovizBase)
source("http://bioconductor.org/biocLite.R")
biocLite("BSgenome")
?alphabetFrequency
reqSeq = getSeq(erbs)
library(BSgenome)
reqSeq = getSeq(erbs)
erbs = granges(erbs)
erbs
#Q2.8.2
library(BSgenome.Hsapiens.UCSC.hg19)
source("http://bioconductor.org/biocLite.R")
library(BSgenome)
reqSeq = getSeq(erbs)
reqSeq = getSeq(HSapiens, erbs)
HSapiens
Hsapiens
reqSeq = getSeq(Hsapiens, erbs)
reqSeq = getSeq(Hsapiens, HepG2)
?getSeq
helpSeq = getSeq(Hsapiens, HepG2)
HelpG2
HepG2
helpSeq = getSeq(Hsapiens, HepG2)
alphabetFrequency(getSeq(Hsapiens,erbs), baseOnly=T, as.prob=T)
getSeq(Hsapiens, erbs)
biocLite("BSgenome.Hsapiens.UCSC.hg19")
library(BSgenome.Hsapiens.UCSC.hg19)
library(BSgenome)
alphabetFrequency(getSeq(Hsapiens,erbs), baseOnly=T, as.prob=T)
library(BSgenome.Hsapiens.UCSC.hg19)
biocLite("BSgenome")
library(BSgenome)
alphabetFrequency(getSeq(Hsapiens,erbs), baseOnly=T, as.prob=T)
erbs = granges(erbs)
library(ERBS)
data(HepG2)
data(GM12878)
res = findOverlaps(HepG2,GM12878)
erbs = HepG2[queryHits(res)]
erbs = granges(erbs)
alphabetFrequency(getSeq(Hsapiens,erbs), baseOnly=T, as.prob=T)
alphabetFrequency(getSeq(Hsapiens,erbs))
alphaFreq = alphabetFrequency(getSeq(Hsapiens,erbs))
str(alphaFreq)
gcContent = alphaFreq
gcContent$Prop = gcContent[, 'C'] + gcContent[, 'G']
gcContent
gcContent = alphaFreq
gcContent = as.data.frame(alphaFreq)
gcContent
gcContent$Prop = gcContent$G + gcContent$C
gcContent
gcContent = as.data.frame(alphaFreq)
gcContent
gcContent$Prop = (gcContent$G + gcContent$C) / (gcContent$A + gcContent$C + gcContent$G + gcContent$T)
gcContent
median(gcContent$Prop)
controlData = getSeq(Hsapiens, shift(erbs, 1000))
alphaFreq = alphabetFrequency(getSeq(Hsapiens,controlData))
controlData = getSeq(Hsapiens, shift(erbs, 10000))
controlData
erbs
alphaFreq = alphabetFrequency(controlData)
alphaFreq = alphabetFrequency(controlData)[, 2:3]
str(alphaFreq)
n = width(alphaFreq)
n = width(shift(erbs, 10000))
gccontent = rowSums(alphaFreq)/n
median(gccontent)
rm(list = ls())
library(Biostrings)
available.genome()
available.genomes()
grep('Drerio', available.genomes(), ignore.case = TRUE, values = TRUE)
grep('Drerio', available.genomes(), ignore.case = TRUE)
length(grep('Drerio', available.genomes(), ignore.case = TRUE))
?grep
grep('Drerio', available.genomes(), ignore.case = TRUE, value = TRUE)
library(BSgenome.Hsapiens.UCSC.hg19.masked)
biocLite('BSgenome.Hsapiens.UCSC.hg19.masked')
library(BSgenome.Hsapiens.UCSC.hg19.masked)
c17m = BSgenome.Hsapiens.UCSC.hg19.masked$chr17
class(c17m)
c22m = BSgenome.Hsapiens.UCSC.hg19.masked$chr22
length(c22m)
n = length(c22m)
names(c22m)
unique(c22m$desc)
mcols(c22m)
?mcols
masks(c22m)
masks(c22m)$AGAPS
width(masks(c22m)$AGAPS)
sum (width(masks(c22m)$AGAPS))
den = length(c22m)
num = sum (width(masks(c22m)$AGAPS))
ans = 100 * num / den
ans
round(100*sum(width(masks(c22m)$AGAPS))/length(c22m),0)
ans = round(100 * num / den, 0)
ans
"hg19ToHg38.over.chain.gz")
download.file("http://hgdownload.cse.ucsc.edu/goldenPath/hg19/liftOver/hg19ToHg38.over.chain.gz",
"hg19ToHg38.over.chain.gz")
library(R.utils)
gunzip("hg19ToHg38.over.chain.gz")
library(ERBS)
data(HepG2)
library(rtracklayer)
ch = import.chain("hg19ToHg38.over.chain")
nHepG2 = liftOver(HepG2, ch)
hHepG2
nHepG2
start(nHepG2)
start(nHepG2)[[1]]
start(nHepG2)[[1]] - start(HepG2)[[1]]
library(devtools)
install_github("genomicsclass/ph525x")
library(ph525x)
stopifnot(packageVersion("ph525x") >= "0.0.16") # do over if fail
modPlot("ESR1", useGeneSym=FALSE, collapse=FALSE)
ESR1
ESR1
source("http://bioconductor.org/biocLite.R")
biocLite("Gviz")
modPlot("ESR1", useGeneSym=FALSE, collapse=FALSE)
library(Gviz)
biocLite("Gviz")
library(Gviz)
source("http://bioconductor.org/biocLite.R")
biocLite("Gviz")
library(Gviz)
install.packages('acepack')
library(acepack)
install.packages("acepack")
library(acepack)
source("http://bioconductor.org/biocLite.R")
biocLite("Gviz")
library(Gviz)
modPlot("ESR1", useGeneSym=FALSE, collapse=FALSE)
library(BiocInstaller)
biocLite("Gviz")
library(Gviz)
library(acepack)
library(Gviz)
install.packages('Hmisc')
library(Hmisc)
library(Gviz)
rm(list = ls())
library(tm)
getwd()
setwd('/Users/admin/Documents/Coursera/AnalyticsEdge-edX/FinalExam')
getwd()
#Q1
ebay = read.csv('ebay.csv', stringsAsFactors = FALSE)
str(ebay)
nrow(ebay[ebay$sold == 1, ]) / nrow(ebay)
#Q2
summary(ebay)
#Q3
table(ebay$size)
#Q4
ebay$sold = as.factor(ebay$sold)
ebay$condition = as.factor(ebay$condition)
ebay$heel = as.factor(ebay$heel)
ebay$style = as.factor(ebay$style)
ebay$color = as.factor(ebay$color)
ebay$material = as.factor(ebay$material)
#Q5
library(caTools)
set.seed(144)
spl = sample.split(ebay$sold, SplitRatio = 0.7)
ebayTrain = subset(ebay, spl == TRUE)
ebayTest = subset(ebay, spl == FALSE)
#Q6
logModel = glm(sold ~ biddable + startprice + condition + heel + style + color + material,
data = ebayTrain, family = 'binomial')
summary(logModel)
#Q7
biddable = as.integer(0)
startprice = 100
condition = as.factor(as.character('Pre-owned'))
heel = as.factor(as.character('High'))
style = as.factor(as.character('Open Toe'))
color = as.factor(as.character('Black'))
material = as.factor(as.character('Satin'))
mydata = data.frame(biddable, startprice, condition, heel, style, color, material)
predict(logModel, newdata = mydata, type = 'response')
#Q8
(exp(0.8325406) - 1) * 100
#Q9
predictedProb = predict(logModel, newdata = ebayTest, type = 'response')
table(ebayTest$sold, predictedProb > 0.5)
#Q10
library(ROCR)
predictionValues = prediction(predictedProb, ebayTest$sold)
perf.auc = performance(predictionValues, 'auc')
auc = as.numeric(perf.auc@y.values)
auc
#Q13
perf = performance(predictionValues, 'tpr', 'fpr')
plot(perf, colorize = TRUE)
#Q15
install.packages('caret')
library(caret)
library(e1071)
set.seed(144)
numFolds = trainControl(method = 'cv', number = 10)
cpGrid = expand.grid(.cp = seq(from = 0.001, to = 0.05, length.out = 50))
train(sold ~ biddable + startprice + condition + heel + style + color + material,
data = ebayTrain, method = 'rpart', trControl = numFolds, tuneGrid = cpGrid)
#Q16
library(rpart)
library(rpart.plot)
ebayCART = rpart(sold ~ biddable + startprice + condition + heel + style + color + material,
data = ebayTrain, method = 'class', cp = 0.005)
prp(ebayCART)
#Q17
library(tm)
library(SnowballC)
corpus = Corpus(VectorSource(ebay$description))
corpus[[1]]
ebay$description[1]
corpus = Corpus(VectorSource(ebay$description[1]))
corpus[[1]]
corpus = Corpus(VectorSource(ebay$description))
corpus[[1]]
corpus = tm_map(corpus, tolower)
corpus[[1]]
corpus = tm_map(corpus, PlainTextDocument)
corpus = tm_map(corpus, removePunctuation)
corpus[[1]]
corpus = Corpus(VectorSource(ebay$description))
corpus[[1]]
corpus = tm_map(corpus, tolower)
corpus[[1]]
corpus = tm_map(corpus, removePunctuation)
corpus[[1]]
corpus = tm_map(corpus, removeWords, stopwords('English'))
corpus[[1]]
corpus = tm_map(corpus, stemDocument)
corpus[[1]]
corpus[[2]]
corpus = Corpus(VectorSource(ebay$description))
corpus[[1]]
corpus = tm_map(corpus, tolower)
corpus[[1]]
corpus = tm_map(corpus, PlainTextDocument)
corpus = tm_map(corpus, removePunctuation)
corpus[[1]]
corpus = tm_map(corpus, removeWords, stopwords('English'))
corpus[[1]]
corpus = tm_map(corpus, stemDocument)
corpus[[2]]
corpus[[1]]
freq = DocumentTermMatrix(corpus)
freq
dtm = DocumentTermMatrix(corpus)
dtm
inspect(dtm)
dtm
inspect(dtm[1000:1005,505:515])
sparse = removeSparseTerms(dtm, 0.90)
sparse
spdtm = removeSparseTerms(dtm, 0.90)
spdtm
descriptionText = as.data.frame(as.matrix(spdtm))
sort(table(descriptionText))
str(descriptionText)
sort(colsums(descriptionText))
sort(colSums(descriptionText))
names(descriptionText) = past0('D', names(descriptionText))
names(descriptionText) = paste0('D', names(descriptionText))
descriptionText$sold = ebay$sold
descriptionText$biddable = ebay$biddable
descriptionText$startprice = ebay$startprice
descriptionText$condition = ebay$condition
descriptionText$heel = ebay$heel
descriptionText$style = ebay$style
descriptionText$color = ebay$color
descriptionText$material = ebay$material
spl = sample.split(descriptionText$sold, SplitRatio = 0.7)
trainText = subset(descriptionText, spl == TRUE)
trainTest = subset(descriptionText, spl == FALSE)
str(trainTest)
testText = subset(descriptionText, spl == FALSE)
set.seed(144)
spl = sample.split(descriptionText$sold, SplitRatio = 0.7)
trainText = subset(descriptionText, spl == TRUE)
testText = subset(descriptionText, spl == FALSE)
str(testText)
#Q21
glmText = glm(sold ~ ., data = trainText, family = binomial)
summary(glmText)
textPred = predict(glmText, newdata = testText, type = 'response')
textPredictions = prediction(textPred, testText$sold)
perf.auc = performance(textPredictions, 'auc')
auc = as.numeric(perf.auc@y.values)
auc
testAUC = as.numeric(perf.auc@y.values)
testAUC
trainPred = predict(glmText, type = 'response')
trainPredictions = prediction(trainPred, trainText$sold)
perf.aucTrain = performance(trainPredictions, 'auc')
trainAUC = as.numeric(perf.aucTrain$y.values)
trainAUC
trainAUC = as.numeric(perf.aucTrain@y.values)
trainAUC
rm(list = ls())
getwd()
setwd("/Users/admin/Documents/Coursera/AnalyticsEdge-edX/FinalExam")
getwd()
hubwayData = read.csv('HuvwayTrips.csv')
hubwayData = read.csv('HubwayTrips.csv')
str(hubwayData)
nrow(hubwayData)
mean(hubwayData$Duration)
mean(hubwayData[hubwayData$Weekday == 1, 'Duration'])
mean(hubwayData[hubwayData$Weekday == 0, 'Duration'])
table(hubwayData$Morning)
table(hubwayData$Afternoon)
table(hubwayData$Evening)
length(hubwayData$Male == 1)
length(hubwayData$Male[hubwayData$Male == 1])
length(hubwayData$Male[hubwayData$Male == 1]) / nrow(hubwayData)
str(hubwayData)
library(caret)
preproc = preProcess(hubwayData)
hubwayNorm = predict(preproc, hubwayData)
max(hubwayNorm$Duration)
max(hubwayNorm$Age)
k = 10
set.seed(5000)
hubwayKMC = kmeans(hubwayData, centers = k)
str(hubwayKMC)
table(hubwayKMC$cluster)
sort(table(hubwayKMC$cluster))
min(table(hubwayKMC$cluster))
which.min(table(hubwayKMC$cluster))
sort(table(hubwayKMC$cluster))
k = 10
set.seed(5000)
hubwayKMC = kmeans(hubwayNorm, centers = k)
str(hubwayKMC)
sort(table(hubwayKMC$cluster))
str(huwayKMC$centers)
str(hubwayKMC$centers)
class(hubwayKMC$centers)
hubwayKMC$centers
str(hubwayKMC)
hubwayKMC$cluster
hubwayKMC[hubwayKMC$cluster == 2]
hubwayKMC$centers[1]
hubwayKMC$cluster[1]
hubwayKMC$cluster
str(hubwayData)
hubwayData[hubwayData$Male == 0 & hubwayData$Weekday == 1 & hubwayData$Evening == 1, ]
str(hubwayData[hubwayData$Male == 0 & hubwayData$Weekday == 1 & hubwayData$Evening == 1, ])
which(hubwayData[hubwayData$Male == 0 & hubwayData$Weekday == 1 & hubwayData$Evening == 1, ])
rownum(hubwayData[hubwayData$Male == 0 & hubwayData$Weekday == 1 & hubwayData$Evening == 1, ])
rowNum(hubwayData[hubwayData$Male == 0 & hubwayData$Weekday == 1 & hubwayData$Evening == 1, ])
str(hubwayData[hubwayData$Male == 0 && hubwayData$Weekday == 1 && hubwayData$Evening == 1, ])
head(hubwayData[hubwayData$Male == 0 & hubwayData$Weekday == 1 & hubwayData$Evening == 1, ])
hubwaySubset = hubwayData[hubwayData$Male == 0 & hubwayData$Weekday == 1 & hubwayData$Evening == 1, ]
head(hubwaySubset)
unique(hubwaySubset$Male)
unique(hubwaySubset$Weekday)
unique(hubwaySubset$Evening)
head(rowNames(hubwaySubset))
head(row.names(hubwaySubset))
head(as.numeric(row.names(hubwaySubset)))
hubwayKMC$cluster[as.numeric(row.names(hubwaySubset))]
unique(hubwayKMC$cluster[as.numeric(row.names(hubwaySubset))])
hubwayKMC$centers
meanDuration = mean(hubwayData$Duration)
hubwayDuration$Weekday == 0, ]
hubwaySub = hubwayData[hubwayData$Duration > meanDuration & hubwayData$Afternoon == 1 &
hubwayData$Weekday == 0, ]
unique(hubwayKMC$clusters[as.numeric(row.names(hubwaySub))])
hubwayKMC$clusters[as.numeric(row.names(hubwaySub))]
head(hubwaySub)
head(as.numeric(row.names(hubwaySub)))
hubwayKMC$cluster[as.numeric(row.names(hubwaySub))]
table(hubwayKMC$cluster[as.numeric(row.names(hubwaySub))])
table(hubwayKMC$cluster[as.numeric(row.names(hubwaySubset))])
table(hubwayKMC$cluster[as.numeric(row.names(hubwaySub))])
meanAge = mean(hubwayData$Age)
hubwaySub2 = hubwayData[hubwayData$Morning == 1 & hubwayData$Age > meanAge, ]
str(hubwaySub2)
table(hubwayKMC$cluster[as.numeric(row.names(hubwaySub2))])
k = 20
set.seed(8000)
hubwayKMC2 = kmeans(hubwayNorm, centers = k)
table(hubwayKMC2$clusters)
hubwayKMC2
str(hubwayKMC2)
table(hubwayKMC2$cluster)
sort(table(hubwayKMC2$cluster))
hubwaySub3 = hubwayData[hubwayData$Duration < meanDuration & hubwayData$Weekday == 1 &
hubwayData$Evening == 1, ]
table(hubwayKMC2$cluster[as.numeric(row.names(hubwaySub3))])
unique(hubwaySub3$Evening)
unique(hubwaySub3$Weekday)
table(hubwayKMC2$cluster[as.numeric(row.names(hubwaySub3))])
as.numeric(row.names(hubwaySub3))
head(as.numeric(row.names(hubwaySub3)))
head(as.numeric(row.names(hubwaySub2)))
as.numeric(row.names(hubwaySub))
head(as.numeric(row.names(hubwaySub)))
head(as.numeric(row.names(hubwaySub3)))
head(as.numeric(row.names(hubwaySub)))
head(as.numeric(row.names(hubwaySub2)))
table(hubwayKMC2$cluster[as.numeric(row.names(hubwaySub3))])
hubwaySub3 = hubwayData[hubwayData$Duration < meanDuration & hubwayData$Evening == 1 &
hubwayData$Weekday == 1, ]
head(as.numeric(row.names(hubwaySub3)))
head(hubwayKMC2$cluster[as.numeric(row.names(hubwaySub3))])
unique(hubwayKMC2$cluster[as.numeric(row.names(hubwaySub3))])
hubwayKMC2$cluster
unique(hubwayKMC2$cluster[as.numeric(row.names(hubwaySub3))])
boxplot(hubwayData$Age, hubwayKMC$cluster)
boxplot(hubwayKMC$cluster, hubwayData$Age)
library(cluster)
library(HSAUR)
data(pottery)
km    <- kmeans(pottery,3)
dissE <- daisy(pottery)
dE2   <- dissE^2
sk2   <- silhouette(km$cl, dE2)
plot(sk2)
plot(hubwayData$Age, col = hubwayKMC$cluster)
plot(hubwayData$Age ~ hubwayKMC$cluster, col = hubwayKMC$cluster)
boxplot(hubwayData$Age ~ hubwayKMC$cluster)
boxplot(hubwayKMC$cluster ~ hubwayData$Age)
install.packages('ggplot')
install.packages('ggplot2')
install.packages('ggplot2')
install.packages("ggplot2")
library(ggplot2)
library(ggplot2)
hubData = hubwayData
hubData$cluster = hubwayKMC$cluster
ggplot(hubwayDat, aes(x = Age, y = cluster)) + geom_histogram()
ggplot(hubwayData, aes(x = Age, y = cluster)) + geom_histogram()
str(hubData)
ggplot(hubData, aes(x = Age, y = cluster)) + geom_histogram()
ggplot(hubData, aes(x = Age, y = cluster)) + geom_point()
unique(hubwayKMC$cluster[as.numeric(row.names(hubwaySub3))])
table(hubwayKMC2$cluster[as.numeric(row.names(hubwaySub3))])
