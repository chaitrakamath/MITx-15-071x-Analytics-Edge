svmfit = svm (y ~ ., data = dat, cost = 0.1, kernel = 'linear', scale = FALSE)
plot(svmfit, dat)
svmfit$index
summary(svmfit)
set.seed(1)
tune.out = tune(svm, y ~ ., data = dat, kernel = 'linear', ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100,)))
tune.out = tune(svm, y ~ ., data = dat, kernel = 'linear', ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100)))
tune.out=tune(svm,y∼.,data=dat,kernel="linear",              ranges=list(cost=c(0.001, 0.01, 0.1, 1,5,10,100)))
tune.out=tune(svm,y∼.,data=dat,kernel="linear",ranges=list(cost=c(0.001, 0.01, 0.1, 1,5,10,100)))
tune.out=tune(svm,y ~.,data=dat,kernel="linear",ranges=list(cost=c(0.001, 0.01, 0.1, 1,5,10,100)))
?tune()
tune.out = tune(svm, y~., data = dat, ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100)), kernel = 'linear')
tune(svm, Species~., data = iris, ranges = list(gamma = 2^(-1:1), cost = 2^(2:4)),tunecontrol = tune.control(sampling = "fix"))
xtest = matrix(rnorm(20 * 2), ncol = 2)
ytest = sample(c(-1, 1), 20, rep = TRUE)
xtest[ytest == 1, ] = xtest[ytest == 1, ] + 1
testdat = data.frame(xtest, ytest = as.factor(ytest))
bestmod = svm(y ~ ., data = dat, kernel = 'linear', cost = 0.1)
ypred = predict(bestmod, newdata = testdat)
ypred
table(predict = ypred, truth = testdat$ytest)
bestmod = svm(y ~ ., data = dat, kernel = 'linear', cost = 0.1, scale = FALSE)
ypred = predict(bestmod, newdata = testdat)
table(predict = ypred, truth = testdat$ytest)
svmfit = svm(y ~ ., data = dat, kernel = 'linear', cost = 0.01, scale = FALSE)
set.seed(1)
bestmod = svm(y ~ ., data = dat, kernel = 'linear', cost = 0.1, scale = FALSE)
xtest = matrix(rnorm(20 * 2), ncol = 2)
ytest = sample(c(-1, 1), 20, rep = TRUE)
xtest[ytest == 1, ] = xtest[ytest == 1, ] + 1
bestmod = svm(y ~ ., data = dat, kernel = 'linear', cost = 0.1, scale = FALSE)
table(predict = ypred, truth = testdat$ytest)
ypred = predict(svmfit, newdata = testdat)
table(ypred, testdat$ytest)
x[y == 1, ] = x[y == 1, ] + 0.5
plot(x, col = (y + 5) / 2, pch = 19)
dat = data.frame(x, y = as.factor(y))
svmfit = svm(y ~ ., data = dat, kernle = 'linear', cost = 1e5)
summary(svmfit)
plot(svmfit, dat)
svmfit = svm(y ~ ., data = dat, kernle = 'linear', cost = 1)
summary(svmfit)
plot(svmfit, dat)
set.seed(1)
x = matrix(rnorm(20 * 2), ncol = 2)
set.seed(1)
x = matrix(rnorm(200 * 2), ncol = 2)
x[1:100, ] = x[1:100, ] + 2
x[101:150, ] = x[101:150, ] - 2
?sample()
y = c(rep(1, 150), rep(2, 50))
dat = data.frame(x, y = as.factor(y))
plot(x, col = y)
train = sample(200, 100)
svmfit = svm (y ~ ., data = dat[train,], kernel = 'radial', gamma = 1, cost = 1)
plot(svmfit, dat[train,])
summary(svmfit)
svmfit = svm (y ~ ., data = dat[train,], kernel = 'radial', gamma = 1, cost = 1e5)
plot(svmfit, dat[train,])
summary(svmfit)
set.seed(1)
tune.out = tune(svm, y~., data = dat[train,], ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100)), gamma = c(0.5, 1, 2, 3, 4), kernel = 'radial')
set.seed(1)
tune.out=tune(svm, y~., data=dat[train,], kernel="radial",ranges=list(cost=c(0.1,1,10,100,1000),gamma=c(0.5,1,2,3,4) ))
tune.out=tune(svm, y~., data=dat[train,], kernel="radial",ranges=list(cost=c(0.1,1,10,100,100),gamma=c(0.5,1,2,3,4)))
set.seed(1)
bestmod = svm(y ~ ., data = dat[train,], cost = 1, gamma = 2, kernel = 'radial')
table(pred = predict(bestmod, newdata =dat[-train,]), true = dat[-train, 'y'])
library(ROCR)
install.packages('ROCR')
library(ROCR)
rocplot = function(pred, truth, ...){
predob = predict(pred, truth)
}
rocplot = function(pred, truth, ...){
predob = prediction(pred, truth)
perf = performance(predob, 'tpr', 'fpr')
plot(perf, ...)
}
svmfit.opt = svm (y ~ ., data = dat[train,], kernel = 'radial', gamma = 2, cost = 1, decision.values = TRUE)
fitted = attributes(svmfit.opt, newdata = dat[-train,], decision.values = TRUE)
fitted = attributes(predict(svmfit.opt, newdata = dat[-train,], decision.values = TRUE))
names(fitted)
fitted$decision.values
fitted$class
names(fitted)
fitted$levels
fitted$names
par(mfrow = c(1,2))
rocplot(fitted, dat[train, 'y'], main = 'Training data')
rocplot(fitted ,dat[train ,"y"],main="Training Data")
rocplot=function(pred, truth, ...){    predob = prediction (pred, truth)    perf = performance (predob , "tpr", "fpr") plot(perf ,...)}
rocplot=function(pred, truth, ...){predob = prediction (pred, truth)    perf = performance (predob , "tpr", "fpr") plot(perf ,...)}
rocplot=function(pred, truth, ...){
predob = prediction (pred, truth)
perf = performance (predob , "tpr", "fpr")
plot(perf ,...)
}
rocplot(fitted, dat[train, 'y'], main = 'Training data')
fitted$decision.values
length(fitted$decision.values)
length(dat[train, 'y'])
str(dat)
dat$y = as.numeric(levels(dat$y))
str(dat)
rocplot(fitted, dat[train, 'y'], main = 'Training data')
str(dat[train, 'y'])
str(fitted$decision.values)
as.numeric(fitted$decision.values)
str(as.numeric(fitted$decision.values))
rocplot(as.numeric(fitted$decision.values), dat[train, 'y'], main = 'Training data')
dat$y = as.factor(dat$y)
str(dat)
svmfit.flex = svm(y ~ ., data = dat[train, ], kernel = 'radial', gamma = 50, cost = 1, decision.values = T)
fitted = attributes(predict(svmfit.flex, newdata = dat[-train, y], decision.values = T))$decision.values
rocplot(fitted, dat[train, 'y'], add = 'T', col = 'red')
svmfit.opt = svm(y ~ ., data = dat[train,], kernel = 'radial', cost = 1, gamma = 2)
svmfit.opt = svm(y ~ ., data = dat[train,], kernel = 'radial', cost = 1, gamma = 2, decision.values = T)
fitted = attributes(predict(svmfit.opt, x[-train, 'y'], decision.values = T))$decision.values
fitted = attributes(predict(svmfit.opt, x[-train,], decision.values = T))$decision.values
rocplot(fitted, dat[-train, 'y'], main = 'Test Data')
fitted = attributes(predict(svmfit.flex, x[-train,], decision.values = T))$decision.values
rocplot(fitted, dat[-train, 'y'], add = 'T', col = 'red')
set.seed(1)
x = rbind(x, matrix(rnorm(50)))
x = rbind(x, matrix(rnorm(50*2), ncol = 2))
str(x
)
x
class(x)
y = c(y, rep(0, 50))
x[y == 0, ] = x[y == 0, ] + 2
dat = data.frame(x, as.factor(y))
par(mfrow= c(1, 2))
par(mfrow= c(1, 1))
plot(x, col = y)
plot(x, col = (y + 1))
plot(x, col = (y + 1))
plot(x, col = (y + 1))
plot(x, col = y)
plot(x, col = (y + 1))
smvfit = svm(y ~ ., data = dat, kernel = 'radial', cost = 10, gamma = 1)
plot(svmfit, dat)
library(ISLR)
names(Khan)
dim(xtrain)
dim(Khan$xtrain)
class(Khan)
class(Khan$xtrain)
dim(Khan$xtest)
length(Khan$ytrain)
length(Khan$ytest)
data = data.frame(x = Khan$xtrain, y = as.factor(Khan$ytrain))
head(data)
dat = data.frame(x = Khan$xtrain, y = as.factor(Khan$ytrain))
out = svm(ytrain ~ ., data = dat, kernel = 'linear', cost = 10)
out = svm(y ~ ., data = dat, kernel = 'linear', cost = 10)
summary(out)
plot(out, dat)
table(out$fitted, dat$y)
dat.test = data.frame(x = Khan$xtest, y = as.factor(Khan$ytest))
pred.test = predict(out, newdata = dat.test)
table(pred.test, dat.test$y)
rnorm(10, mean = 0)
rnorm(10, mean = 0, sd = diag(10))
rnorm(10, mean = 0, sd = diag(10))
rnorm(10, mean = 0, sd = diag(10))
rnorm(10, mean = 0, sd = diag(10))
rnorm(10, mean = 0, sd = diag(10))
matrix(rnorm(10, mean = 0, sd = diag(10),  10, 10)
)
matrix(rnorm(10, mean = 0, sd = diag(10)),  10, 10)
matrix(rnorm(100, mean = 0, sd = diag(10)),  10, 10)
diag(3)
matrix(rnorm(100, mean = rep(0,10), sd = diag(10)),  10, 10)
rep(0,10)
x2 = matrix(rnorm(100, mean = c(1,1,1,1,1,0,0,0,0,0), sd = diag(10)), 10, 10)
x2
y=rep(c(-1,1),c(10,10))
y
x1 = matrix(rnorm(100, mean = rep(0,10), sd = diag(10)),  10, 10)
x2 = matrix(rnorm(100, mean = c(1,1,1,1,1,0,0,0,0,0), sd = diag(10)), 10, 10)
x1
x2
rbind(x1, x2)
beta0 = -1.5
beta1 = 3
beta2 = -0.5
x1 = 1
x2 = 5
beta0 + beta1 * x1 + beta2 * x2
e^-1
exp(-1)
1/ (1 + exp(1))
pwd
getwd()
setwd('/Users/admin/Documents/Coursera/AnalyticsEdge-edX/Week3/Lecture')
getwd()
quality = read.csv('quality.csv')
str(quality)
table(quality$PoorCare)
98 / 13
98 / 131
install.packages('caTools')
load(caTools)
library(caTools)
set.seed(88)
split = sample.split(quality$PoorCare, SplitRatio = 0.75)
head(split)
qualityTrain = subset(quality, split == TRUE)
qualityTest = subset(quality, split == FALSE)
nrow(qualityTrain)
nrow(qualityTest)
qualityLog = glm(PoorCare ~ OfficeVisits + Narcotics, data = qualityTrain, family = binomial)
summary(qualityLog)
predictTrain = predict(qualityLog, type = 'response')
summary(predictTrain)
tapply(predictTrain, qualitTrain$PoorCare, mean)
tapply(predictTrain, qualityTrain$PoorCare, mean)
qualityLog = glm(PoorCare ~ StartedOnCombination + ProviderCount, data = qualityTrain, family = binomial)
summary(qualityLog)
table(qualityTrain$PoorCare, predictTrain > 0.5)
install.packages('ROCR')
library(ROCR)
ROCRPred = prediction(predictTrain, qualityTrain$PoorCare)
ROCRPerf = performance (ROCRPred, 'tpr', 'fpr')
plot(ROCRPerf)
plot(ROCRPerf, colorize = TRUE)
plot(ROCRPerf, colorize = TRUE, print.cutoff.at = seq(0,1,0.1), text.adj = c(-0.2, 1.7))
plot(ROCRPerf, colorize = TRUE, print.cutoff.at = seq(0,1,0.1), text.adj = c(-0.2, 1.7))
plot(ROCRPerf, colorize = TRUE, print.cutoffs.at = seq(0,1,0.1), text.adj = c(-0.2, 1.7))
plot(ROCRPerf, colorize = TRUE, print.cutoffs.at = seq(0,1,0.1))
plot(ROCRPerf, colorize = TRUE, print.cutoffs.at = seq(0,1,0.1), text.adj = c(-0.2, 1.7))
qualityLog = glm (PoorCare ~ OfficeVisits + Narcotics, data = qualityTrain, family = binomial)
predictTest = predict(qualityLog, newdata = qualityTest, type = 'response')
ROCPredTest = prediction(predictTest, qualityTest$PoorCare)
auc = as.numeric(performance(ROCPredTest, 'auc')@y.values)
auc
framingham = read.csv('framingham.csv')
str(framingham)
library(caTools)
set.seed(1000)
split = sample.split(farmingham$TenYearCHD, SplitRatio = 0.6)
split = sample.split(framingham$TenYearCHD, SplitRatio = 0.6)
farminghamTrain = subset (framingham, split == TRUE)
farminghamTest = subset (framingham, split == FALSE)
framinghamLog = glm(TenYearCHD ~ ., data = framinghamTrain, family = binomial)
framinghamLog = glm(TenYearCHD ~ ., data = farminghamTrain, family = binomial)
summary(framinghamLog)
set.seed(1000)
split = sample.split(framingham$TenYearCHD, SplitRatio = 0.6)
farminghamTrain = subset (framingham, split == TRUE)
farminghamTest = subset (framingham, split == FALSE)
framinghamLog = glm(TenYearCHD ~ ., data = farminghamTrain, family = binomial)
summary(framinghamLog)
predictTest = predict(framinghamLog, newdata = farminghamTest, type = 'response')
table(farminghamTest$TenYearCHD, predictTest > 0.5)
(1215 + 11) / 4240
(1215 + 11) / (4240 * 0.4)
(1215 + 11) / (1215 + 9 + 11 + 211)
library(ROCR)
ROCRPred = prediction(predictTest, farminghamTest$TenYearCHD)
as.numeric(performance(ROCRPred, 'auc')@y.values)
polling = read.csv('PollingData.csv')
str(polling)
table(polling$Year)
summary(polling)
install.packages('mice')
library(mice)
simple = polling[c('Rasmussen', 'SurveyUSA', 'PropR', 'DiffCount')]
summary(simple)
set.seed(144)
imputed = complete(mice(simple))
summary(imputed)
simple$Rasmussen = imputed$Rasmussen
simple$SummaryUSA = imputed$SummaryUSA
summary(simple)
polling$SummaryUSA = imputed$SummaryUSA
polling$Rasmussen = imputed$Rasmussen
summary(polling)
polling$SurveyUSA = imputed$SurveyUSA
summary(polling)
train = subset(polling, Year %in% (2004, 2008))
train = subset(polling, Year %in% c(2004, 2008))
summary(train)
unique(train$Year)
test = subset (polling, Year == 2012)
table(train$Republican)
table(test$Republican)
table(sign(train$Rasmussen))
table(Train$Republican, sign(train$Rasmussen))
table(train$Republican, sign(train$Rasmussen))
cor(train[c(-'State')])
cor(train[!'State'])
cor(train[!c('State')])
cor(train[c(-'State')])
cor(train[c(-1)])
modl = glm (Republican ~ PropR, data = train, family = binomial)
summary(modl)
pred1 = predict(modl, type = 'response')
table(train$Republican, pred1 >= 0.5)
mod2 = glm (Republican ~ DiffCount + SurveyUSA, data = train, family = binomial)
summary(mod2)
pred2 = predict(mod2, type = 'response')
table(train$Republican, pred2 >= 0.5)
table(test$Republican, sign(test$Rasmussen))
testPred = predict(mod2, newdata = test, type = 'response')
table(test$Republican, testPred >= 0.5)
subset(test, testPred >= 0.5 & Republican == 0)
getwd()
setwd('/Users/admin/Documents/Coursera/AnalyticsEdge-edX/Week3/Assignment')
getwd()
#1.1
songs = read.csv('songs.csv')
str(songs)
nrow(subset(songs, year == 2010))
nrow(subset(songs, artistname == 'Michael Jackson'))
subset(songs, artistname == 'Michael Jackson' & Top10 == 1)[, 'songtitle']
unique(songs[, 'timesignature'])
sort(unique(songs[, 'timesignature']))
sort(table(songs[, 'timesignature']))
tapply(songs$tempo, songs$songtitle, max)
head(subset(songs, select = c(songtitle, tempo) ))
str(songs)
nrow(unique(songs$songtitle))
length(unique(songs$songtitle))
songs[which.max(songs$tempo), 'songtitle']
songsTrain = subset(songs, year <= 2009)
str(songsTrain)
songsTest =  subset(songs, year > 2009)
novars = c('year', 'songtitle', 'songID', 'artistID', 'artistname')
songsTrain = songsTrain[, !(names(songsTrain %in% novars))]
songsTrain = songsTrain[, (names(songsTrain) %in% novars)]
songsTest = songsTest[, (names(songsTest) %in% novars)]
str(songsTrain)
songsTrain = subset(songs, year <= 2009)
str(songsTrain)
songsTest =  subset(songs, year > 2009)
#2.2
novars = c('year', 'songtitle', 'songID', 'artistID', 'artistname')
songsTrain = songsTrain[, !(names(songsTrain) %in% novars)]
songsTest = songsTest[, !(names(songsTest) %in% novars)]
str(songsTrain)
str(songsTest)
songsModel1 = glm (Top10 ~ ., data = songsTrain, family = binomial)
summary(songsModel1)
cor(songsTrain$loudness, songsTrain$energy)
songsModel2 = glm(Top10 ~ . - loudness, data = songsTrain, family = binomial)
summary(songsModel2)
summary(songsModel1)
songsModel3 = glm (Top10 ~ .-energy, data = songsTrain, family = binomial)
summary(songsModel3)
testPredict = predict(songsModel3, newdata = songsTest, type = 'response')
head(testPredict)
table(songsTest$Top10, testPredict > 0.45)
accuracy = (309 + 19) / (309 + 5 + 40 + 19)
accuracy
table(songsTest$Top10, testPredict > 0.45)
table(songsTest$Top10)
309 / 314
309 / (309 + 5)
314 / (314 + 59)
table(songsTest$Top10, testPredict > 0.45)
sensitivity = 19 / (19 + 40)
specificity = 309 / (309 + 5)
sensitivity
specificity
getwd()
setwd('/Users/admin/Documents/Coursera/AnalyticsEdge-edX/Week3/Assignment')
getwd()
#1.1
paroles = read.csv('parole.csv')
str(paroles)
summary(paroles)
length(paroles$violator == 1)
length(paroles[paroles$violators == 1, paroles$violators])
unique(paroles$violators)
length(paroles[paroles$violator == 1, paroles$violator])
summary(paroles)
paroles$state = as.factor(paroles$state)
paroles$crime = as.factor(paroles$crime)
summary(paroles)
set.seed(144)
library(caTools)
split = sample.split(paroles$violator, SplitRatio = 0.7)
paroleTrain = subset(paroles, split == TRUE)
paroleTest = subset(paroles, split == FALSE)
str(paroleTrain)
paroleModel = glm (violator ~ ., data = paroleTrain, family = binomial)
summary(paroleModel)
-4.2411574 + 0.3869904 + 0.8867192 - 0.0001756 * 50 + 0 - 0.1238867 * 3 + 0.0802954 * 12 + 0.6837143
exp(-1.700629)
log(-1.700629)
test2 = data.frame(t(c(1,1,50,1,3,12,0,2,1)))
names(test2) = names(paroleTest)
predict(paroleModel, newdata = test2, type = 'response')
test2
head(paroleTest)
test2 = data.frame(t(c(1,1,50,as.fact(1),3,12,0,as.factor(2),1)))
test2 = data.frame(t(c(1,1,50,as.factor(1),3,12,0,as.factor(2),1)))
names(test2) = names(paroleTest)
predict(paroleModel, newdata = test2, type = 'response')
test2 = data.frame(t(c(1,1,50,as.factor(1),3,12,0,as.factor(2),1)))
names(test2) = names(paroleTest)
str(test2)
str(test2$crime)
test2 = data.frame(t(c(1,1,50,1,3,12,0,2,1)))
names(test2) = names(paroleTest)
test2$crime = as.factor(test2$crime)
test2$state = as.factor(test2$state)
predict(paroleModel, newdata = test2, type = 'response')
prob.y1 = predict(paroleModel, newdata = test2, type = 'response')
prob.y1
prob.y0 = 1 - prob.y1
prob.y1 / prob.y0
prob.y0
predictTest = predict(paroleModel, newdata = paroleTest, type = 'response')
max(predictTest)
table(paroleTest$violator, predictTest > 0.5)
sensitivity = 12 / (11 + 12)
specificity = 167 / (167 + 12)
sensitivity = 12 / (11 + 12)
sensitivity
specificity = 167 / (167 + 12)
specificity
accuracy = (167 + 12) / (167 + 12 + 11 + 12)
accuracy
table(paroleTest$violator)
179 / (179 + 23)
library(ROCR)
ROCRPred = prediction (predictTest, paroleTest$violator)
ROCRPerf = performance(ROCRPred, 'tpr', 'fpr')
as.numeric(performance(ROCRpred, "auc")@y.values)
as.numeric(performance(ROCRPred, "auc")@y.values)
loans = read.csv('loans.csv')
str(loans)
summary(loans)
unique(loans$not.fully.paid)
table(loans$not.fully.paid)
prop = 1533 / (1533 + 8045)
prop
loansImp = read.csv('loans_imputed.csv')
set.seed(144)
vars.for.imputation = setdiff(names(loans), "not.fully.paid")
vars.for.imputation
imputed = complete(mice(loans[vars.for.imputation]))
loans[vars.for.imputation] = imputed
?mice()
?complete()
set.seed(144)
library(caTools)
split = sample.split(loans$not.fully.paid, SplitRatio = 0.7)
loansTrain = subset(loans, split == TRUE)
loansTest = subset(loans, split == FALSE)
loansModel = glm (not.fully.paid ~ ., data = loansTrain, family = 'binomial')
summary(loansModel)
-9.406e-03 * 10
exp(700 * -9.406e-03) / exp(710 * -9.406e-03)
-9.406e-03 * 10
predictedRisk = predict(loansModel, newdata = loansTest, type = 'response')
table(loansTest$not.fully.paid, predictedRisk > 0.5)
accuracy = (2400 + 3) / (2400 + 13 + 457 + 3)
accuracy
table(loansTest$not.fully.paid)
accuracy = 460 / (2413 + 460)
accuracy
accuracy = 2413 / (2413 + 460)
accuracy
ROCRPred = prediction (predictedRisk, loansTest$not.fully.paid)
ROCRPerf = performance(ROCRPred, 'tpr', 'fpr')
as.numeric(performance(ROCRPred, "auc")@y.values)
model2 = glm(not.fully.paid ~ int.rate, data = loansTrain, family = binomial)
summary(model2)
loanPredict = predict(model2, newdata = loansTest, type = 'response')
max(loanPredict)
table(loansTest$not.fully.paid, loanPredict > 0.5)
table(loansTest$not.fully.paid, loanPredict > 0.5)
library(ROCR)
ROCRPred = prediction (loanPredict, loansTest$not.fully.paid)
ROCRPerf = performance(ROCRPred, 'tpr', 'fpr')
as.numeric(performance(ROCRPred, "auc")@y.values)
loansTest$profit = exp(loansTest$int.rate*3) - 1
loansTest$profit[loansTest$not.fully.paid == 1] = -1
max(loansTest$profit) * 10
highInterest = subset(loansTest, int.rate >= -.15)
mean(highInterest$profit)
table(highInterest$not.paid.fully)
names(highInterest)
table(highInterest$not.fully.paid)
460 / (460 + 2413)
2413 / (460 + 2413)
460 + 2413
str(highInterest)
str(loansTest)
highInterest$predicted.risk = predictedRisk
names(highInterest)
cutoff = sort(highInterest$predicted.risk, decreasing=FALSE)[100]
selectedLoans = subset(highInterest, predicted.risk < cutoff)
str(selectedLoans)
sum(selectedLoans$profit)
table(selectedLoans$not.fully.paid)
2/100
10 * exp(0.06 * 3)
table(loansTest$not.fully.paid, loanPredict > 0.5)
table(loansTest$not.fully.paid, loanPredict < 0.5)
length(loanPredict)
nrow(loansTest)
nrow(loansTrain)
length(loanPredict[loanPredict > 0.5])
head(loanPredict)
max(loanPredict)
table(loansTest$not.fully.paid, loanPredict > 0.5)
