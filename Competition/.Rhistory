plot (x)
plot(x, col = (3 - y))
dat = data.frame(x, y = as.factor(y))
install.packages('e1071')
library(e1071)
svmfit = svm (y ~ ., data = dat, cost = 10, kernel = 'linear', scale = FALSE)
plot(svmfit, dat)
plot.svm(svmfit, dat)
dat
names(svmfit)
svmfit$index
summary(svmfit)
svmfit = svm (y ~ ., data = dat, cost = 0.1, kernel = 'linear', scale = FALSE)
plot(svmfit, dat)
svmfit$index
summary(svmfit)
set.seed(1)
tune.out = tune(svm, y ~ ., data = dat, kernel = 'linear', ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100,)))
tune.out = tune(svm, y ~ ., data = dat, kernel = 'linear', ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100)))
tune.out=tune(svm,y∼.,data=dat,kernel="linear",              ranges=list(cost=c(0.001, 0.01, 0.1, 1,5,10,100)))
tune.out=tune(svm,y∼.,data=dat,kernel="linear",ranges=list(cost=c(0.001, 0.01, 0.1, 1,5,10,100)))
tune.out=tune(svm,y ~.,data=dat,kernel="linear",ranges=list(cost=c(0.001, 0.01, 0.1, 1,5,10,100)))
?tune()
tune.out = tune(svm, y~., data = dat, ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100)), kernel = 'linear')
tune(svm, Species~., data = iris, ranges = list(gamma = 2^(-1:1), cost = 2^(2:4)),tunecontrol = tune.control(sampling = "fix"))
xtest = matrix(rnorm(20 * 2), ncol = 2)
ytest = sample(c(-1, 1), 20, rep = TRUE)
xtest[ytest == 1, ] = xtest[ytest == 1, ] + 1
testdat = data.frame(xtest, ytest = as.factor(ytest))
bestmod = svm(y ~ ., data = dat, kernel = 'linear', cost = 0.1)
ypred = predict(bestmod, newdata = testdat)
ypred
table(predict = ypred, truth = testdat$ytest)
bestmod = svm(y ~ ., data = dat, kernel = 'linear', cost = 0.1, scale = FALSE)
ypred = predict(bestmod, newdata = testdat)
table(predict = ypred, truth = testdat$ytest)
svmfit = svm(y ~ ., data = dat, kernel = 'linear', cost = 0.01, scale = FALSE)
set.seed(1)
bestmod = svm(y ~ ., data = dat, kernel = 'linear', cost = 0.1, scale = FALSE)
xtest = matrix(rnorm(20 * 2), ncol = 2)
ytest = sample(c(-1, 1), 20, rep = TRUE)
xtest[ytest == 1, ] = xtest[ytest == 1, ] + 1
bestmod = svm(y ~ ., data = dat, kernel = 'linear', cost = 0.1, scale = FALSE)
table(predict = ypred, truth = testdat$ytest)
ypred = predict(svmfit, newdata = testdat)
table(ypred, testdat$ytest)
x[y == 1, ] = x[y == 1, ] + 0.5
plot(x, col = (y + 5) / 2, pch = 19)
dat = data.frame(x, y = as.factor(y))
svmfit = svm(y ~ ., data = dat, kernle = 'linear', cost = 1e5)
summary(svmfit)
plot(svmfit, dat)
svmfit = svm(y ~ ., data = dat, kernle = 'linear', cost = 1)
summary(svmfit)
plot(svmfit, dat)
set.seed(1)
x = matrix(rnorm(20 * 2), ncol = 2)
set.seed(1)
x = matrix(rnorm(200 * 2), ncol = 2)
x[1:100, ] = x[1:100, ] + 2
x[101:150, ] = x[101:150, ] - 2
?sample()
y = c(rep(1, 150), rep(2, 50))
dat = data.frame(x, y = as.factor(y))
plot(x, col = y)
train = sample(200, 100)
svmfit = svm (y ~ ., data = dat[train,], kernel = 'radial', gamma = 1, cost = 1)
plot(svmfit, dat[train,])
summary(svmfit)
svmfit = svm (y ~ ., data = dat[train,], kernel = 'radial', gamma = 1, cost = 1e5)
plot(svmfit, dat[train,])
summary(svmfit)
set.seed(1)
tune.out = tune(svm, y~., data = dat[train,], ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100)), gamma = c(0.5, 1, 2, 3, 4), kernel = 'radial')
set.seed(1)
tune.out=tune(svm, y~., data=dat[train,], kernel="radial",ranges=list(cost=c(0.1,1,10,100,1000),gamma=c(0.5,1,2,3,4) ))
tune.out=tune(svm, y~., data=dat[train,], kernel="radial",ranges=list(cost=c(0.1,1,10,100,100),gamma=c(0.5,1,2,3,4)))
set.seed(1)
bestmod = svm(y ~ ., data = dat[train,], cost = 1, gamma = 2, kernel = 'radial')
table(pred = predict(bestmod, newdata =dat[-train,]), true = dat[-train, 'y'])
library(ROCR)
install.packages('ROCR')
library(ROCR)
rocplot = function(pred, truth, ...){
predob = predict(pred, truth)
}
rocplot = function(pred, truth, ...){
predob = prediction(pred, truth)
perf = performance(predob, 'tpr', 'fpr')
plot(perf, ...)
}
svmfit.opt = svm (y ~ ., data = dat[train,], kernel = 'radial', gamma = 2, cost = 1, decision.values = TRUE)
fitted = attributes(svmfit.opt, newdata = dat[-train,], decision.values = TRUE)
fitted = attributes(predict(svmfit.opt, newdata = dat[-train,], decision.values = TRUE))
names(fitted)
fitted$decision.values
fitted$class
names(fitted)
fitted$levels
fitted$names
par(mfrow = c(1,2))
rocplot(fitted, dat[train, 'y'], main = 'Training data')
rocplot(fitted ,dat[train ,"y"],main="Training Data")
rocplot=function(pred, truth, ...){    predob = prediction (pred, truth)    perf = performance (predob , "tpr", "fpr") plot(perf ,...)}
rocplot=function(pred, truth, ...){predob = prediction (pred, truth)    perf = performance (predob , "tpr", "fpr") plot(perf ,...)}
rocplot=function(pred, truth, ...){
predob = prediction (pred, truth)
perf = performance (predob , "tpr", "fpr")
plot(perf ,...)
}
rocplot(fitted, dat[train, 'y'], main = 'Training data')
fitted$decision.values
length(fitted$decision.values)
length(dat[train, 'y'])
str(dat)
dat$y = as.numeric(levels(dat$y))
str(dat)
rocplot(fitted, dat[train, 'y'], main = 'Training data')
str(dat[train, 'y'])
str(fitted$decision.values)
as.numeric(fitted$decision.values)
str(as.numeric(fitted$decision.values))
rocplot(as.numeric(fitted$decision.values), dat[train, 'y'], main = 'Training data')
dat$y = as.factor(dat$y)
str(dat)
svmfit.flex = svm(y ~ ., data = dat[train, ], kernel = 'radial', gamma = 50, cost = 1, decision.values = T)
fitted = attributes(predict(svmfit.flex, newdata = dat[-train, y], decision.values = T))$decision.values
rocplot(fitted, dat[train, 'y'], add = 'T', col = 'red')
svmfit.opt = svm(y ~ ., data = dat[train,], kernel = 'radial', cost = 1, gamma = 2)
svmfit.opt = svm(y ~ ., data = dat[train,], kernel = 'radial', cost = 1, gamma = 2, decision.values = T)
fitted = attributes(predict(svmfit.opt, x[-train, 'y'], decision.values = T))$decision.values
fitted = attributes(predict(svmfit.opt, x[-train,], decision.values = T))$decision.values
rocplot(fitted, dat[-train, 'y'], main = 'Test Data')
fitted = attributes(predict(svmfit.flex, x[-train,], decision.values = T))$decision.values
rocplot(fitted, dat[-train, 'y'], add = 'T', col = 'red')
set.seed(1)
x = rbind(x, matrix(rnorm(50)))
x = rbind(x, matrix(rnorm(50*2), ncol = 2))
str(x
)
x
class(x)
y = c(y, rep(0, 50))
x[y == 0, ] = x[y == 0, ] + 2
dat = data.frame(x, as.factor(y))
par(mfrow= c(1, 2))
par(mfrow= c(1, 1))
plot(x, col = y)
plot(x, col = (y + 1))
plot(x, col = (y + 1))
plot(x, col = (y + 1))
plot(x, col = y)
plot(x, col = (y + 1))
smvfit = svm(y ~ ., data = dat, kernel = 'radial', cost = 10, gamma = 1)
plot(svmfit, dat)
library(ISLR)
names(Khan)
dim(xtrain)
dim(Khan$xtrain)
class(Khan)
class(Khan$xtrain)
dim(Khan$xtest)
length(Khan$ytrain)
length(Khan$ytest)
data = data.frame(x = Khan$xtrain, y = as.factor(Khan$ytrain))
head(data)
dat = data.frame(x = Khan$xtrain, y = as.factor(Khan$ytrain))
out = svm(ytrain ~ ., data = dat, kernel = 'linear', cost = 10)
out = svm(y ~ ., data = dat, kernel = 'linear', cost = 10)
summary(out)
plot(out, dat)
table(out$fitted, dat$y)
dat.test = data.frame(x = Khan$xtest, y = as.factor(Khan$ytest))
pred.test = predict(out, newdata = dat.test)
table(pred.test, dat.test$y)
rnorm(10, mean = 0)
rnorm(10, mean = 0, sd = diag(10))
rnorm(10, mean = 0, sd = diag(10))
rnorm(10, mean = 0, sd = diag(10))
rnorm(10, mean = 0, sd = diag(10))
rnorm(10, mean = 0, sd = diag(10))
matrix(rnorm(10, mean = 0, sd = diag(10),  10, 10)
)
matrix(rnorm(10, mean = 0, sd = diag(10)),  10, 10)
matrix(rnorm(100, mean = 0, sd = diag(10)),  10, 10)
diag(3)
matrix(rnorm(100, mean = rep(0,10), sd = diag(10)),  10, 10)
rep(0,10)
x2 = matrix(rnorm(100, mean = c(1,1,1,1,1,0,0,0,0,0), sd = diag(10)), 10, 10)
x2
y=rep(c(-1,1),c(10,10))
y
x1 = matrix(rnorm(100, mean = rep(0,10), sd = diag(10)),  10, 10)
x2 = matrix(rnorm(100, mean = c(1,1,1,1,1,0,0,0,0,0), sd = diag(10)), 10, 10)
x1
x2
rbind(x1, x2)
library(tm)
getwd()
setwd("/Users/admin/Documents/Coursera/AnalyticsEdge-edX/Competition")
getwd()
nyTrain = read.csv('NYTimesBlogTrain.csv', stringsAsFactors = FALSE)
nyTest = read.csv('NYTimesBlogTest.csv', stringsAsFactors = FALSE)
nyTest$Popular = NA
nyMerged = rbind(nyTrain, nyTest)
unique(nyMerged$NewsDesk)
nyMerged$NewsDesk[nyMerged$NewsDesk == ""] = 'Other'
unique(nyMerged$NewsDesk)
library(tm)
#Business Popular Terms
bizPopular = subset(nyMerged, nyMerged$NewsDesk == 'Business' & nyMerged$Popular == 1)
str(bizPopular)
bizPopularHeadlines = Corpus(VectorSource(bizPopular$Headline))
bizPopularHeadlines[[1]]
bizPopularHeadlines = tm_map(bizPopularHeadlines, tolower)
bizPopularHeadlines[[1]]
bizPopularHeadlines = tm_map(bizPopularHeadlines, PlainTextDocument)
bizPopularHeadlines[[1]]
bizPopularHeadlines = tm_map(bizPopularHeadlines, removeWords, stopwords('en'))
bizPopularHeadlines[[1]]
bizPopDTM = DocumentTermMatrix(bizPopularHeadlines)
bizPopDTM
bizPopSparse = removeSparseTerms(bizPopDTM, 0.98)
bizPopSparse
popularBizTerms = names(as.data.frame(as.matrix(bizPopSparse)))
popularBizTerms
#Culture Popular Terms
culturePopular = subset(nyMerged, nyMerged$NewsDesk == 'Culture' & nyMerged$Popular == 1)
str(culturePopular)
culturePopularHeadlines = Corpus(VectorSource(culturePopular$Headline))
culturePopularHeadlines[[1]]
culturePopularHeadlines = tm_map(culturePopularHeadlines, tolower)
culturePopularHeadlines[[1]]
culturePopularHeadlines = tm_map(culturePopularHeadlines, PlainTextDocument)
culturePopularHeadlines[[1]]
culturePopularHeadlines = tm_map(culturePopularHeadlines, removeWords, stopwords('en'))
culturePopularHeadlines[[1]]
culturePopDTM = DocumentTermMatrix(culturePopularHeadlines)
culturePopDTM
culturePopSparse = removeSparseTerms(culturePopDTM, 0.98)
culturePopSparse
popularcultureTerms = names(as.data.frame(as.matrix(culturePopSparse)))
popularcultureTerms
#Science Popular Terms
sciencePopular = subset(nyMerged, nyMerged$NewsDesk == 'Science' & nyMerged$Popular == 1)
str(sciencePopular)
sciencePopularHeadlines = Corpus(VectorSource(sciencePopular$Headline))
sciencePopularHeadlines[[1]]
sciencePopularHeadlines = tm_map(sciencePopularHeadlines, tolower)
sciencePopularHeadlines[[1]]
sciencePopularHeadlines = tm_map(sciencePopularHeadlines, PlainTextDocument)
sciencePopularHeadlines[[1]]
sciencePopularHeadlines = tm_map(sciencePopularHeadlines, removeWords, stopwords('en'))
sciencePopularHeadlines[[1]]
sciencePopDTM = DocumentTermMatrix(sciencePopularHeadlines)
sciencePopDTM
sciencePopSparse = removeSparseTerms(sciencePopDTM, 0.98)
sciencePopSparse
popularscienceTerms = names(as.data.frame(as.matrix(sciencePopSparse)))
popularscienceTerms
#OpEd Popular Terms
opedPopular = subset(nyMerged, nyMerged$NewsDesk == 'OpEd' & nyMerged$Popular == 1)
str(opedPopular)
opedPopularHeadlines = Corpus(VectorSource(opedPopular$Headline))
opedPopularHeadlines[[1]]
opedPopularHeadlines = tm_map(opedPopularHeadlines, tolower)
opedPopularHeadlines[[1]]
opedPopularHeadlines = tm_map(opedPopularHeadlines, PlainTextDocument)
opedPopularHeadlines[[1]]
opedPopularHeadlines = tm_map(opedPopularHeadlines, removeWords, stopwords('en'))
opedPopularHeadlines[[1]]
opedPopDTM = DocumentTermMatrix(opedPopularHeadlines)
opedPopDTM
opedPopSparse = removeSparseTerms(opedPopDTM, 0.99)
opedPopSparse
popularopedTerms = names(as.data.frame(as.matrix(opedPopSparse)))
popularopedTerms
#Other Popular Terms
otherPopular = subset(nyMerged, nyMerged$NewsDesk == 'Other' & nyMerged$Popular == 1)
str(otherPopular)
otherPopularHeadlines = Corpus(VectorSource(otherPopular$Headline))
otherPopularHeadlines[[1]]
otherPopularHeadlines = tm_map(otherPopularHeadlines, tolower)
otherPopularHeadlines[[1]]
otherPopularHeadlines = tm_map(otherPopularHeadlines, PlainTextDocument)
otherPopularHeadlines[[1]]
otherPopularHeadlines = tm_map(otherPopularHeadlines, removeWords, stopwords('en'))
otherPopularHeadlines[[1]]
otherPopDTM = DocumentTermMatrix(otherPopularHeadlines)
otherPopDTM
otherPopSparse = removeSparseTerms(otherPopDTM, 0.98)
otherPopSparse
popularotherTerms = names(as.data.frame(as.matrix(otherPopSparse)))
popularotherTerms
#Foreign Popular Terms
foreignPopular = subset(nyMerged, nyMerged$NewsDesk == 'Foreign' & nyMerged$Popular == 1)
str(foreignPopular)
foreignPopularHeadlines = Corpus(VectorSource(foreignPopular$Headline))
foreignPopularHeadlines[[1]]
foreignPopularHeadlines = tm_map(foreignPopularHeadlines, tolower)
foreignPopularHeadlines[[1]]
foreignPopularHeadlines = tm_map(foreignPopularHeadlines, PlainTextDocument)
foreignPopularHeadlines[[1]]
foreignPopularHeadlines = tm_map(foreignPopularHeadlines, removeWords, stopwords('en'))
foreignPopularHeadlines[[1]]
foreignPopDTM = DocumentTermMatrix(foreignPopularHeadlines)
foreignPopDTM
foreignPopSparse = removeSparseTerms(foreignPopDTM, 0.98)
foreignPopSparse
popularforeignTerms = names(as.data.frame(as.matrix(foreignPopSparse)))
popularforeignTerms
#Styles Popular Terms
stylePopular = subset(nyMerged, nyMerged$NewsDesk == 'Styles' & nyMerged$Popular == 1)
str(stylePopular)
stylePopularHeadlines = Corpus(VectorSource(stylePopular$Headline))
stylePopularHeadlines[[1]]
stylePopularHeadlines = tm_map(stylePopularHeadlines, tolower)
stylePopularHeadlines[[1]]
stylePopularHeadlines = tm_map(stylePopularHeadlines, PlainTextDocument)
stylePopularHeadlines[[1]]
stylePopularHeadlines = tm_map(stylePopularHeadlines, removeWords, stopwords('en'))
stylePopularHeadlines[[1]]
stylePopDTM = DocumentTermMatrix(stylePopularHeadlines)
stylePopDTM
stylePopSparse = removeSparseTerms(stylePopDTM, 0.98)
stylePopSparse
popularstyleTerms = names(as.data.frame(as.matrix(stylePopSparse)))
popularstyleTerms
#TStyle Popular Terms
tStylePopular = subset(nyMerged, nyMerged$NewsDesk == 'TStyle' & nyMerged$Popular == 1)
str(tStylePopular)
tStylePopularHeadlines = Corpus(VectorSource(tStylePopular$Headline))
tStylePopularHeadlines[[1]]
tStylePopularHeadlines = tm_map(tStylePopularHeadlines, tolower)
tStylePopularHeadlines[[1]]
tStylePopularHeadlines = tm_map(tStylePopularHeadlines, PlainTextDocument)
tStylePopularHeadlines[[1]]
tStylePopularHeadlines = tm_map(tStylePopularHeadlines, removeWords, stopwords('en'))
tStylePopularHeadlines[[1]]
tStylePopDTM = DocumentTermMatrix(tStylePopularHeadlines)
tStylePopDTM
tStylePopSparse = removeSparseTerms(tStylePopDTM, 0.98)
tStylePopSparse
populartStyleTerms = names(as.data.frame(as.matrix(tStylePopSparse)))
populartStyleTerms
#Magazine Popular Terms -- no popular terms in Magazine
magazinePopular = subset(nyMerged, nyMerged$NewsDesk == 'Magazine' & nyMerged$Popular == 1)
str(magazinePopular)
#Travel Popular Terms
travelPopular = subset(nyMerged, nyMerged$NewsDesk == 'Travel' & nyMerged$Popular == 1)
str(travelPopular)
travelPopularHeadlines = Corpus(VectorSource(travelPopular$Headline))
travelPopularHeadlines[[1]]
travelPopularHeadlines = tm_map(travelPopularHeadlines, tolower)
travelPopularHeadlines[[1]]
travelPopularHeadlines = tm_map(travelPopularHeadlines, PlainTextDocument)
travelPopularHeadlines[[1]]
travelPopularHeadlines = tm_map(travelPopularHeadlines, removeWords, stopwords('en'))
travelPopularHeadlines[[1]]
travelPopDTM = DocumentTermMatrix(travelPopularHeadlines)
travelPopDTM
travelPopSparse = removeSparseTerms(travelPopDTM, 0.99)
travelPopSparse
populartravelTerms = names(as.data.frame(as.matrix(travelPopSparse)))
populartravelTerms
#Metro Popular Terms
metroPopular = subset(nyMerged, nyMerged$NewsDesk == 'Metro' & nyMerged$Popular == 1)
str(metroPopular)
metroPopularHeadlines = Corpus(VectorSource(metroPopular$Headline))
metroPopularHeadlines[[1]]
metroPopularHeadlines = tm_map(metroPopularHeadlines, tolower)
metroPopularHeadlines[[1]]
metroPopularHeadlines = tm_map(metroPopularHeadlines, PlainTextDocument)
metroPopularHeadlines[[1]]
metroPopularHeadlines = tm_map(metroPopularHeadlines, removeWords, stopwords('en'))
metroPopularHeadlines[[1]]
metroPopDTM = DocumentTermMatrix(metroPopularHeadlines)
metroPopDTM
metroPopSparse = removeSparseTerms(metroPopDTM, 0.98)
metroPopSparse
popularmetroTerms = names(as.data.frame(as.matrix(metroPopSparse)))
popularmetroTerms
#National Popular Terms -- no popular terms
nationalPopular = subset(nyMerged, nyMerged$NewsDesk == 'National' & nyMerged$Popular == 1)
str(nationalPopular)
#Sports Popular Terms -- no popular terms
sportsPopular = subset(nyMerged, nyMerged$NewsDesk == 'Sports' & nyMerged$Popular == 1)
str(sportsPopular)
popularTerms = c(popularBizTerms, popularcultureTerms, popularscienceTerms, popularopedTerms,
popularotherTerms, popularstyleTerms, populartStyleTerms, populartravelTerms,
popularmetroTerms)
popularTerms
popularTermsShort = c('amazon', 'apple', 'bankruptcy', "facebook", "goldman", "ios",
'wall ', 'homeland', 'alicia', 'alison', 'ben', 'broadway',
'david', 'joan rivers', 'newsroom', 'taylor swift', 'cancer',
'ebola', 'exercise', "teenagers", "weight", "global warming", "obama",
"republicans", "ferguson", "isis",  "mccartney",
"uber", "jobs", "phone", 'alibaba' ,"microsoft")
grep('microsoft', nyMerged$Headline, ignore.case = TRUE, value = TRUE)
isAmazon = grepl('amazon', nyMerged$Headline, ignore.case = TRUE) + 0
isApple = grepl('apple', nyMerged$Headline, ignore.case = TRUE) + 0
isBankruptcy = grepl('bankruptcy', nyMerged$Headline, ignore.case = TRUE) + 0
isFacebook = grepl('facebook', nyMerged$Headline, ignore.case = TRUE) + 0
isGoldman = grepl('goldman', nyMerged$Headline, ignore.case = TRUE) + 0
isIOS = grepl('ios', nyMerged$Headline, ignore.case = TRUE) + 0
isWall = grepl('wall ', nyMerged$Headline, ignore.case = TRUE) + 0
isHomeland = grepl('homeland', nyMerged$Headline, ignore.case = TRUE) + 0
isAlicia = grepl('alicia', nyMerged$Headline, ignore.case = TRUE) + 0
isAlison = grepl('alison', nyMerged$Headline, ignore.case = TRUE) + 0
isBen = grepl('ben ', nyMerged$Headline, ignore.case = TRUE) + 0
isBroadway = grepl('broadway', nyMerged$Headline, ignore.case = TRUE) + 0
isDavid = grepl('david', nyMerged$Headline, ignore.case = TRUE) + 0
isJoan = grepl('joan rivers', nyMerged$Headline, ignore.case = TRUE) + 0
isNewsroom = grepl('newsroom', nyMerged$Headline, ignore.case = TRUE) + 0
isTaylor = grepl('taylor swift', nyMerged$Headline, ignore.case = TRUE) + 0
isCancer = grepl('cancer', nyMerged$Headline, ignore.case = TRUE) + 0
isEbola = grepl('ebola', nyMerged$Headline, ignore.case = TRUE) + 0
isExercise = grepl('exercise', nyMerged$Headline, ignore.case = TRUE) + 0
isTeenagers = grepl('teenagers', nyMerged$Headline, ignore.case = TRUE) + 0
isWeight = grepl('weight', nyMerged$Headline, ignore.case = TRUE) + 0
isGlobalWarming = grepl('global warming', nyMerged$Headline, ignore.case = TRUE) + 0
isObama = grepl('obama', nyMerged$Headline, ignore.case = TRUE) + 0
isKeystone = grepl('keystone', nyMerged$Headline, ignore.case = TRUE) + 0
isRepublicans = grepl('republicans', nyMerged$Headline, ignore.case = TRUE) + 0
isFerguson = grepl('ferguson', nyMerged$Headline, ignore.case = TRUE) + 0
isISIS = grepl('isis', nyMerged$Headline, ignore.case = TRUE) + 0
isMcCartney = grepl('mccartney', nyMerged$Headline, ignore.case = TRUE) + 0
isUber = grepl('uber', nyMerged$Headline, ignore.case = TRUE) + 0
isJobs = grepl('jobs', nyMerged$Headline, ignore.case = TRUE) + 0
isPhone = grepl('phone', nyMerged$Headline, ignore.case = TRUE) + 0
isAlibaba = grepl('alibaba', nyMerged$Headline, ignore.case = TRUE) + 0
isMicrosoft = grepl('microsoft', nyMerged$Headline, ignore.case = TRUE) + 0
nyAll = cbind(nyMerged, isAmazon, isApple, isBankruptcy, isFacebook, isGoldman, isIOS, isWall,
isHomeland, isAlicia, isAlison, isBen, isBroadway, isDavid, isJoan, isNewsroom,
isTaylor, isCancer, isEbola, isExercise, isTeenagers, isWeight, isGlobalWarming,
isObama, isKeystone, isRepublicans, isFerguson, isISIS, isMcCartney, isUber,
isJobs, isPhone, isAlibaba, isMicrosoft)
allData = nyAll
allData$Headline = NULL
allData$Snippet = NULL
allData$Abstract = NULL
allData$NewsDesk = as.factor(allData$NewsDesk)
allData$SectionName = as.factor(allData$SectionName)
allData$SubsectionName = as.factor(allData$SubsectionName)
allData$Popular = as.factor(allData$Popular)
str(allData)
trainData = subset(allData, is.na(allData$Popular) == FALSE)
str(trainData)
testData = subset(allData, is.na(allData$Popular) == TRUE)
str(testData)
trainData$PubDate = NULL
str(trainData)
testData$PubDate = NULL
testData$Popular = NULL
str(testData)
#Logistic Regression
simpleLogModel = glm(Popular ~ NewsDesk + SectionName + SubsectionName  + WordCount, data = trainData,
family = binomial)
summary(simpleLogModel)
simpleLogPredict = predict(simpleLogModel, type = 'response')
table(trainData$Popular, simpleLogPredict > 0.5)
logModel = glm(Popular ~ ., data = trainData, family = binomial)
summary(logModel)
str(testData)
logPredict = predict(logModel, type = 'response', newdata = testData)
table(trainData$Popular, logPredict > 0.5)
table(trainData$Popular, logPredict)
logPredictTrain = predict(logModel, type = 'response')
table(trainData$Popular, logPredictTrain > 0.5)
(5188 + 750) / nrow(trainData)
str(testData)
logPredict = predict(logModel, type = 'response', newdata = testData)
library(randomForest)
trainRF = trainData
trainRF$Popular = as.numeric(as.character(trainRF$Popular))
str(trainRF)
set.seed(1)
selectedMTry = tuneRF(x = trainRF[ , - trainRF$Popular ], y = trainRF[ , 'Popular'])
set.seed(1)
rfModel = randomForest(Popular ~ ., data = trainRF, ntree = 1000, nodesize = 5, mytry = 12)
rfPredictTrain = predict(rfModel, type = 'response')
table(trainRF$Popular, rfPredictTrain > 0.5)
(5208 + 726) /  nrow(nyTrain)
rfPredict = predict(rfModel, type = 'response', newdata = testData)
#***************************************************************************************
#Ensembled Model - mean of rf and log predictions
ensemblePred = (logPredict + rfPredict) / 2
mySubmission = data.frame(UniqueID = testData$UniqueID, Probability1 = ensemblePred)
head(mySubmission)
write.csv(mySubmission, "LatestSubmission.csv", row.names=FALSE)
mySubmission = data.frame(UniqueID = testData$UniqueID, Probability1 = logPredict)
head(mySubmission)
write.csv(mySubmission, "LatestSubmission-LogPredict.csv", row.names=FALSE)
mySubmission = data.frame(UniqueID = testData$UniqueID, Probability1 = rfPredict)
head(mySubmission)
write.csv(mySubmission, "LatestSubmission-rfPredict.csv", row.names=FALSE)
ensembledPred2 = (2*logPredict + rfPredict)/3
mySubmission = data.frame(UniqueID = testData$UniqueID, Probability1 = ensembledPred2)
head(mySubmission)
write.csv(mySubmission, "LatestSubmission-ensembledv2.csv", row.names=FALSE)
ensembledPred2 = (2*logPredict + rfPredict)/3
mySubmission = data.frame(UniqueID = testData$UniqueID, Probability1 = ensembledPred2)
head(mySubmission)
write.csv(mySubmission, "LatestSubmission-ensembledv2.csv", row.names=FALSE)
ensembledPred2 = (2*logPredict + rfPredict)/3
mySubmission = data.frame(UniqueID = testData$UniqueID, Probability1 = ensembledPred2)
head(mySubmission)
write.csv(mySubmission, "LatestSubmission-ensembledv2.csv", row.names=FALSE)
ensembledPred2 = (2*logPredict + rfPredict)/3
mySubmission = data.frame(UniqueID = testData$UniqueID, Probability1 = ensembledPred2)
head(mySubmission)
write.csv(mySubmission, "LatestSubmission-ensembledv2.csv", row.names=FALSE)
